/********************************************************************************/
/*                                                                              */
/* Program: Mainframe Thermal Image Processor                                   */
/*                                                                              */
/* File: main.cpp                                                               */
/*                                                                              */
/* Author(s): Alex Gribov, Alexander Senckowski, Molly McGuire and Kevin Smida  */
/*                                                                              */
/* All Right Reserved (c) 2017                                                  */
/*                                                                              */
/********************************************************************************/



#include <opencv2/highgui/highgui.hpp>
#include <opencv2/imgproc/imgproc.hpp>
#include <iostream>

/************************** AZS Start Subtraction Method *************************/
#include "subtractionMethod.h"
//opencv
#include "opencv2/imgcodecs.hpp"
#include "opencv2/imgproc.hpp"
#include "opencv2/videoio.hpp"
#include <opencv2/highgui.hpp>
#include <opencv2/video.hpp>
//C
#include <stdio.h>
//C++
#include <iostream>
#include <sstream>
/************************** AZS End Subtraction Method ***************************/
using namespace cv;
using namespace std;
/************************** AZS Start Subtraction Method *************************/
// Global variables
Mat frame; //current frame
Mat fgMaskMOG2; //fg mask fg mask generated by MOG2 method
Ptr<BackgroundSubtractor> pMOG2; //MOG2 Background subtractor
char keyboard; //input from keyboard
/************************** AZS End Subtraction Method ***************************/

/************************** AZS Start Thresholding *******************************/
void on_low_r_thresh_trackbar(int, void *);
void on_high_r_thresh_trackbar(int, void *);
void on_low_g_thresh_trackbar(int, void *);
void on_high_g_thresh_trackbar(int, void *);
void on_low_b_thresh_trackbar(int, void *);
void on_high_b_thresh_trackbar(int, void *);

int low_r = 30, low_g = 30, low_b = 30;
int high_r = 100, high_g = 100, high_b = 100;
/************************** AZS END Thresholding *********************************/

void processVideo(char* videoFilename);	//AZS
void thresholding(char* videoFilename);	//AZS

int main(int argc, char* argv[])
{
	const std::string sampleStreamAddress = "http://66.193.157.18/mjpg/video.mjpg";

	//create GUI windows
	namedWindow("Frame");
	namedWindow("FG Mask MOG 2");
	//create Background Subtractor objects
	pMOG2 = createBackgroundSubtractorMOG2(); //MOG2 approach

	processVideo("http://66.193.157.18/mjpg/video.mjpg");

	thresholding("http://66.193.157.18/mjpg/video.mjpg");

	//destroy GUI windows
	destroyAllWindows();
	return EXIT_SUCCESS;
}

/************************** AZS Start Subtraction Method *************************/
void processVideo(char* videoFilename) {
	//create the capture object
	VideoCapture capture(videoFilename);
	if (!capture.isOpened()) {
		//error in opening the video input
		cerr << "Unable to open video file: " << videoFilename << endl;
		exit(EXIT_FAILURE);
	}
	//read input data. ESC or 'q' for quitting
	keyboard = 0;
	while (keyboard != 'q' && keyboard != 27) {
		//read the current frame
		if (!capture.read(frame)) {
			cerr << "Unable to read next frame." << endl;
			cerr << "Exiting..." << endl;
			exit(EXIT_FAILURE);
		}
		//update the background model
		pMOG2->apply(frame, fgMaskMOG2);
		//get the frame number and write it on the current frame
		stringstream ss;
		rectangle(frame, cv::Point(10, 2), cv::Point(100, 20),
			cv::Scalar(255, 255, 255), -1);
		ss << capture.get(CAP_PROP_POS_FRAMES);
		string frameNumberString = ss.str();
		putText(frame, frameNumberString.c_str(), cv::Point(15, 15),
			FONT_HERSHEY_SIMPLEX, 0.5, cv::Scalar(0, 0, 0));
		//show the current frame and the fg masks
		imshow("Frame", frame);
		imshow("FG Mask MOG 2", fgMaskMOG2);
		//get the input from the keyboard
		keyboard = (char)waitKey(30);
	}
	//delete capture object
	capture.release();
}
/************************** AZS End Subtraction Method ***************************/

/************************** AZS Start Thresholding *******************************/
void thresholding(char* videoFilename)	//AZS Modified
{
	Mat frame, frame_threshold;
	VideoCapture cap(videoFilename);
	//VideoCapture capture(videoFilename);

	namedWindow("Video Capture", WINDOW_NORMAL);
	namedWindow("Object Detection", WINDOW_NORMAL);
	//-- Trackbars to set thresholds for RGB values
	createTrackbar("Low R", "Object Detection", &low_r, 255, on_low_r_thresh_trackbar);
	createTrackbar("High R", "Object Detection", &high_r, 255, on_high_r_thresh_trackbar);
	createTrackbar("Low G", "Object Detection", &low_g, 255, on_low_g_thresh_trackbar);
	createTrackbar("High G", "Object Detection", &high_g, 255, on_high_g_thresh_trackbar);
	createTrackbar("Low B", "Object Detection", &low_b, 255, on_low_b_thresh_trackbar);
	createTrackbar("High B", "Object Detection", &high_b, 255, on_high_b_thresh_trackbar);
	while ((char)waitKey(1) != 'q') {
		cap >> frame;
		if (frame.empty())
			break;
		//-- Detect the object based on RGB Range Values
		inRange(frame, Scalar(low_b, low_g, low_r), Scalar(high_b, high_g, high_r), frame_threshold);
		//-- Show the frames
		imshow("Video Capture", frame);
		imshow("Object Detection", frame_threshold);
	}
}

void on_low_r_thresh_trackbar(int, void *)
{
	low_r = min(high_r - 1, low_r);
	setTrackbarPos("Low R", "Object Detection", low_r);
}
void on_high_r_thresh_trackbar(int, void *)
{
	high_r = max(high_r, low_r + 1);
	setTrackbarPos("High R", "Object Detection", high_r);
}
void on_low_g_thresh_trackbar(int, void *)
{
	low_g = min(high_g - 1, low_g);
	setTrackbarPos("Low G", "Object Detection", low_g);
}
void on_high_g_thresh_trackbar(int, void *)
{
	high_g = max(high_g, low_g + 1);
	setTrackbarPos("High G", "Object Detection", high_g);
}
void on_low_b_thresh_trackbar(int, void *)
{
	low_b = min(high_b - 1, low_b);
	setTrackbarPos("Low B", "Object Detection", low_b);
}
void on_high_b_thresh_trackbar(int, void *)
{
	high_b = max(high_b, low_b + 1);
	setTrackbarPos("High B", "Object Detection", high_b);
}
/************************** AZS END Thresholding *********************************/

//int main(int argc, char* argv[]) {
//
//	// FIXME: In the future all declarations will be in file globals.h, but I left this here for now so everyone can see how the stream works.
//	VideoCapture cap;		// Number is the ID of video device.
//
//	//*****************************************************//
//	// BEGIN SETUP                                         //
//	//*****************************************************//
//
//	// FIXME: Future home of FLIR ONE address
//	const std::string videoStreamAddress = "http://192.168.0.117:8080/cam_1.mjpg";
//	// Address of sample video feed
//	const std::string sampleStreamAddress = "http://66.193.157.18/mjpg/video.mjpg";
//
//	// Load the videostrem into VideoCapture object.
//	cap.open(sampleStreamAddress);
//	if (!cap.isOpened())  // If not success, exit program
//	{
//		cout << "Cannot open the video cam" << endl;
//		return -1;
//	}
//
//	// Not yet needed, but may be useful
//	double dWidth = cap.get(CV_CAP_PROP_FRAME_WIDTH); //get the width of frames of the video
//	double dHeight = cap.get(CV_CAP_PROP_FRAME_HEIGHT); //get the height of frames of the video
//
//	cout << "Frame size : " << dWidth << " x " << dHeight << endl;
//
//	// Create output windows for displaying video
//	namedWindow("MyVideo", CV_WINDOW_AUTOSIZE); //create a window called "MyVideo"
//	namedWindow("MyNegativeVideo", CV_WINDOW_AUTOSIZE);
//
//	//*****************************************************//
//	// BEGIN SETUP                                         //
//	//*****************************************************//
//
//	//*****************************************************//
//	// BEGIN EXECUTION                                     //
//	//*****************************************************//
//
//	// While loop is main program body -- Gets image from stream, operates on it, then repeats
//	// Loop breaks when user hits "esc" key
//	while (1) {
//		Mat frame;
//		Mat contours;
//
//		bool bSuccess = cap.read(frame); // Read a new frame from video
//
//		if (!bSuccess) { // If not success, break loop
//			cout << "Cannot read a frame from video stream" << endl;
//			break;
//		}
//
//		flip(frame, frame, 1);
//		imshow("MyVideo", frame); //show the frame in "MyVideo" window
//
//		// Sample image processing
//		Canny(frame, contours, 500, 1000, 5, true);
//		imshow("MyNegativeVideo", contours);
//
//		if (waitKey(30) == 27) {//wait for 'esc' key press for 30ms. If 'esc' key is pressed, break loop
//			cout << "esc key is pressed by user" << endl;
//			break;
//		}
//	}
//	return 0;
//}

//// TEST FUNCTION, IGNORE THIS:
//void connectToCamera() {
//	VideoCapture stream(0);		// Number is the ID of video device.
//	stream.set(CV_CAP_PROP_FOURCC, CV_FOURCC('M', 'J', 'P', 'G'));
//	stream.set(CV_CAP_PROP_FRAME_WIDTH, 1920);
//	stream.set(CV_CAP_PROP_FRAME_HEIGHT, 1080);
//
//	if (!stream.isOpened()) { //check if video device has been initialised
//		cout << "cannot open camera";
//	}
//
//	//unconditional loop
//	while (true) {
//		Mat cameraFrame;
//		stream.read(cameraFrame);
//		imshow("cam", cameraFrame);
//		if (waitKey(30) >= 0)
//			break;
//	}
//}